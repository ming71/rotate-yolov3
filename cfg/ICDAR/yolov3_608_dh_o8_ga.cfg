[net]
# Testing
#batch=1
#subdivisions=1
# Training
batch=16
subdivisions=1
width=512
height=512
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.001
burn_in=1000
max_batches = 500200
policy=steps
steps=400000,450000
scales=.1,.1

[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

# Downsample

[orconv]
batch_normalize=1
filters=64
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=leaky

[orconv]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

# Downsample

[orconv]
batch_normalize=1
filters=128
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

[orconv]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

[orconv]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

# Downsample
# s=8
[orconv]
batch_normalize=1
filters=256
size=3
stride=2
pad=1
activation=leaky

# --SE block---
[ga]
channels=256 

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[orconv]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-4
activation=linear

[ga]
channels=256 

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[orconv]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-4
activation=linear

[ga]
channels=256 

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[orconv]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-4
activation=linear

[ga]
channels=256 

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[orconv]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-4
activation=linear

[ga]
channels=256 

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[orconv]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-4
activation=linear

[ga]
channels=256 

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[orconv]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-4
activation=linear

[ga]
channels=256 

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[orconv]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-4
activation=linear

[ga]
channels=256 

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[orconv]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-4
activation=linear

# Downsample
# s=16
[orconv]
batch_normalize=1
filters=512
size=3
stride=2
pad=1
activation=leaky

[ga]
channels=512 

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[orconv]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-4
activation=linear

[ga]
channels=512 

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[orconv]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-4
activation=linear

[ga]
channels=512 

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[orconv]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-4
activation=linear

[ga]
channels=512 

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[orconv]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-4
activation=linear

[ga]
channels=512 

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[orconv]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-4
activation=linear

[ga]
channels=512 

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[orconv]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-4
activation=linear

[ga]
channels=512

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[orconv]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-4
activation=linear

[ga]
channels=512 

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[orconv]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-4
activation=linear

# Downsample
# s=32
[orconv]
batch_normalize=1
filters=1024
size=3
stride=2
pad=1
activation=leaky

[ga]
channels=1024 

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[orconv]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-4
activation=linear

[ga]
channels=1024 

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[orconv]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-4
activation=linear

[ga]
channels=1024 

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[orconv]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-4
activation=linear


[ga]
channels=1024 

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[orconv]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-4
activation=linear

######## backbone到此为止 ##############


[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

[head]
nO = 8
na = 72
classes=1


# 角度定义为x+ 0; 顺时针; 正负0.5pi
[yolo]
mask = 144-215
anchors = utils/kmeans/icdar_608_care.txt
classes=1
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1


[route]
layers = -4

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[upsample]
stride=2

[route]
layers = -1, 77



[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

[head]
nO = 8
na = 72
classes=1


[yolo]
mask = 72-143
anchors = utils/kmeans/icdar_608_care.txt
classes=1
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1



[route]
layers = -4

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[upsample]
stride=2

[route]
layers = -1, 44



[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

[head]
nO = 8
na = 72
classes=1


[yolo]
mask = 0-71
anchors = utils/kmeans/icdar_608_care.txt
classes=1
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1
